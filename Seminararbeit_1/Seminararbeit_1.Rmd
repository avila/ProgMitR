---
title: 'Programmieren mit R: Seminararbeit_1'
author:
- Daniyar Akhmetov
- Marcelo Rainho Avila
- Xuan Son Le
date: 'Abgabedatum: 14/11/2017'
output:
  pdf_document:
    keep_tex: yes
    latex_engine: pdflatex
    number_sections: yes
    toc: yes
    toc_depth: 3
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
graphics: yes
lof: no
fontsize: 12
documentclass: article
---
\newpage
# Part I (3 Points)  

## Tasks  
* *What are the atomic vector types in R? Explain which value they can take and give an example!*
* *What is the difference between generic and atomic vectors?*
* *Explain the following statement: A data frame is a list, but not every list is a data frame.*  

## Answer 
  
1. Atomic vectors are linear vectors (one-dimensional), which consists of values 
of the same type.

**Atomic vectors** | **Values**                          | **Examples**
-------------------|-------------------------------------|---------------
logical            | TRUE/FALSE                          | c(TRUE,FALSE)
integer            | integer numbers                     | c(1L, 10L, 100L)
numeric            | real numbers                        | c(-26, 1.3, -0.25)
complex            | complex numbers a+bi                | c(-2+3i, -4i, 0i)
character          | letters or words                    | c("Hello","R","How are you")
raw                | raw bytes (as pairs of hex digits)  | as.raw(255) = ff

2. Generic vectors (lists) are also linear vectors (one-dimensional), 
but can contain objects of different types. Example of a list: 
```{r}
x <- list(1:10,"a", c(TRUE,FALSE), c(1 + 2i,3i))
str(x)
```

3. A data frame is a list of atomic vectors of the same length and therefore has a two dimensional structure based on rows and columns. Example of a data frame:
```{r}
df <- data.frame(nickName = c(1, 'B','X'), 
                 hasGlasses = c(FALSE,"No","Yes"),
                 bankAmount = c(800,1.2,-20))
df # the different data types are coerced into one unique data type.
```
Data frame is a list of lists with the same length. Each list from a data frame 
represents a column or a row of a data frame. But a list can not be a data frame 
because lists are linear vectors in one dimensional space. 
That's why we have the statement.

# Part II (7 Points) 
## Task
* *Explain each line of the following code. In addition, discuss what the output of identical(a, b) will be. Check the help files for the functions set.seed, identical, rnorm and cumsum.*
* *system.time returns the time elapsed for the computation. Explain the differences:*  
```{r, results="hide"}
  # ensure that results from a random generator are reproducible
set.seed(1)
  # generate a vector of normally distributed random numbers
largeVector <- rnorm(100, mean = 5, sd = 10) 
  # define a and b
a <- cumsum(largeVector)[1:100] 
b <- cumsum(largeVector[1:100])
  # is a equal to b?
identical(a, b) 

system.time(cumsum(largeVector)[1:100])
system.time(cumsum(largeVector)[1:100])
```
## Answer  
  
* Because we ran the function set.seed before, the result of randomly choosen largeVector is reproducible for a and b. This means we are now working with the only one largeVector. 
* A *cumulative sum (cumsum)* is a sequence of partial sums of a given sequence.  
For instance:   
cumsum(largeVector)  
= cumsum(c(k1,k2,k3,...,kn))  
= k1  k1+k2  k1+k2+k3  ...  k1+k2+k3+..+kn  
  
* In a we firstly have a cumulative sum of largeVector and then take the first 100 elements from it:  
a = cumsum(largeVector)[1:100]  
a = (k1  k1+k2  k1+k2+k3 ...  k1+k2+k3+...+kn)[1:100]  
a =  k1  k1+k2  k1+k2+k3 ...  k1+k2+k3+...+k100  
  
* In b we firstly take the first 100 elements from largeVector and then calculate the cumulative sum of these 100 elements.  
b = cumsum(largeVector[1:100])  
b = cumsum(k1 k2 k3 ... k100)  
b = k1  k1+k2  k1+k2+k3 ...  k1+k2+k3+...+k100  

* Now let see why we get different results when applying the function system.time to a and b. On the one hand, *system.time(cumsum(largeVector)[1:100])* firstly try to calculate the cumulative sum of the whole largeVector, which contains 10^8 elements. This would take R a while to finish. On the other hand, *system.time(cumsum(largeVector[1:100]))* firstly get the first 100 elements of largeVector and then calculate the cumulative sum of these 100 elements, which would be much faster to run. That's why we have the difference. 

# Part III (20 Points)
## Task
*Conduct a regression analysis and report your findings. The report should contain the following sections:*
* *data import* 
* *descriptive statistics and data validation*
* *identification of relevant regressors*
* *fitting a regression model*
* *discussion of model fit, e.g. goodness of fit, significance of regressors*
* *interpreting the model*
## Answer
**We decided on a logistic regression with the data set titanic:**  
### Data import
Firstly we need to import all neccessary libraries
```{r, message = FALSE, results = "hide"}
library(ggplot2)
# install.packages("gridExtra")
library(gridExtra)
# install.packages(("Hmisc"))
library(Hmisc)
```

Load titanic data
```{r}
load(file = "/Users/XuanSon/Desktop/titanic.Rdata")
```

### Descriptive statistics and data validation  

Get the data description
``` {r ,introDescribe, message=FALSE, results="hide"}
  # get dataset description
describe(titanic)
```
**Let's summarize the results:**  
  
* Regarding the given values:  
    + So we have 1309 observations with 14 features in total.
    + Only 38,2% of 1309 passengers survived. There are more male (843) than female (466) in this data set
    + The average age of these passengers is about 30.
    + The fare varies between 0 and 512 British Pound. 
    + A large majority of passengers embarks on the titanic in Southampton.

* Regarding missing values:  
    + The feature *age* contains about 20% missing values. We assume that Age does have influence on predicting the survival, so we will try to handle these missing values later on.
    + The varibale *body* contains about 91% missing values. It is quite a high amount. Probably we would drop this feature out of our model.
    + The amounts of missing vales of *fare* and *embarked* are very small. Maybe we would just drop the concerned passengers from the data set or replace the missing values by one certain value.
    + The feature *cabin* also contain a large amount of missing values (1014). We wonder if this feature should necessarily be filled. Let do it in the next step.

Since data frame aims to describes the survival status of individual passengers on the Titanic dependent on many different features, let's take a closer look at the relationships between our target feature *survived* and the explanatory features through some useful plots.  
  
```{r, fig.width=3,fig.height=1.5}
  # Transform some features, which are given as a vector
titanic$age <- as.numeric(titanic$age)
titanic$fare <- as.numeric(titanic$fare)
titanic$sibsp <- as.numeric(titanic$sibsp)
titanic$parch <- as.numeric(titanic$parch)

  # Some features also need to be factorized, so that numeric values 
  # (for example 1,2,3) should not be treated as number but as category. 
titanic$pclass <- factor(titanic$pclass)
titanic$survived <- factor(titanic$survived,levels = c(0,1),labels = c("No","Yes"))
titanic$sex <- factor(titanic$sex)
titanic$embarked <- factor(titanic$embarked) 
```

We use barplots for categorial features:  
```{r, fig.height=4, fig.width=12, warning=FALSE}
p1 <- ggplot(titanic, aes(x = sex, fill = survived)) + 
    geom_bar() + 
    labs(subtitle = "Survival by Sex", y = "No. of passengers", x = " ") +
    ylim(0,1000)

p2 <- ggplot(titanic, aes(x = pclass,fill = survived)) + 
    geom_bar() + 
    labs(subtitle = "Survival by Passenger class", y = "No. of passengers", x = " ") + 
    ylim(0,1000)
    
p3 <- ggplot(titanic, aes(x = sibsp, fill = survived)) + 
    geom_bar() + 
    labs(subtitle = "Survival by Number of\nSiblings/Spouses Aboard ", 
         y = "No. of passengers", x = " ") + ylim(0,1000)

p4 <- ggplot(titanic, aes(x = parch, fill = survived)) + geom_bar() +
    labs(subtitle = "Survival by Number of\nParents/Children Aboard ", 
         y = "No. of passengers", x = " ") 

grid.arrange(p1,p2,p3,p4,ncol = 4)
```

For metric features *age* and *fare* we use boxplots.  
```{r, fig.height=5, fig.width=8, warning=FALSE}
p5 <- ggplot(titanic, aes(y = age, x = survived, fill = survived)) +
    geom_boxplot() +
    labs(subtitle = "Boxplot age", y = "Age", x = " ")

p6 <- ggplot(titanic, aes(y = fare, x = survived, fill = survived)) + 
    geom_boxplot() +
    labs(subtitle = "Boxplot fare", y = "Fares", x = " ") 

grid.arrange(p5,p6,ncol = 2)
```
  
We learn the following things from these plots:  
* *sex*: Females have a much higher chance of survival than males. The *sex* feature is important in our predictions
* *pclass*: Passengers from 3rd class are less likely to survive than those from 1st and 2rd class.  
* *sibsp* and *parch*: having too many siblings/spouses/parents/children on board or travelling alone would decrease the chance of surviving. Travelling with one or two family members would be better in this case.
* Feature *fare* and *age* contains some outliers, which should be treated later.

The outlier values of *fare* and *age*.
```{r eval=FALSE}
sort(boxplot(na.omit(titanic$age))$out) # outlier from 67 years old
sort(boxplot(na.omit(titanic$fare))$out) # outlier from 66,6 British Pound
```
  
It could be also helpful to take a look at the relationship of explanatory features:

```{r}
dropValue <- c("name","cabin","ticket","boat","body","home.dest")
corDataframe <- titanic[ , !(names(titanic) %in% dropValue)] 
corDataframe <- sapply(corDataframe, function(x) x <- as.integer(x))
cor(na.omit(corDataframe))
```
  
+ Our target feature *survived* correlates mostly to *sex* and *pclass*, followed by *fare* and *embarked*. 
+ *pclass* and *fare* correlates strongly negative to each other. So the first class is more expensive than second and third class.
+ *pclass* also correlates quite strongly with *age*. But it could also be a spurious correlation.
+ *sibsp* and *parch* also correlate, since both declare family size

Let us show some multiple relationships graphically:
```{r, fig.height=6, fig.width=8, warning=FALSE}
p7 <- ggplot(titanic,aes(pclass, fill = survived)) + 
    facet_grid( ~ sex) + 
    geom_bar() + labs(subtitle = "Survival by sex and passenger class",
                      y = "No. of passengers")

p8 <- ggplot(titanic,aes(x = pclass, fill = survived)) +
    facet_grid( ~ embarked) + geom_bar(position = "dodge") + 
    labs(subtitle = "Survival by embarked and passenger class", 
         y = "No. of passengers", x = "")

p9 <- ggplot(titanic, aes(y = fare, x = survived, fill = survived)) +
    facet_grid( ~ pclass) + 
    geom_boxplot() + 
    labs(subtitle = "Survival by fare and passenger class",
         y = "Fare") 

p10 <- ggplot(titanic, aes(y = age, x = survived, fill = survived)) +
    facet_grid( ~ pclass) + geom_boxplot() + 
    labs(subtitle = "Survival by age and passenger class",
         y = "Age") 

grid.arrange(p7, p8, p9, p10, ncol = 2)

```
  
+ Female passengers in the first and second class are mostly survived, meanwhile men in all classes have a similar chance of survival, which is quite low. 
+ A major of passenger embarked in Southampton. Most of them did not survive, especially those in second and third classes. 
+ Unsurprisingly the first class is the most expensive one. The average fare of survived passengers is also higher in the first and second classes. This information could be better explained if we have more information about the relationship between *pclass* and *cabin*.
+ The average age of first class passenger (regardless of survival) is higher than the rest.

That might be enough with plots. Let's move to the next step to choose the most important features for our models.

### Identification of relevant regressors
Since some features do not to contain a lot useful information to our model, we would drop them from our model. These are: *name, cabin, ticket, boat, body, home.dest*  
+ We assume that the name of a passenger does not have any influence on his/her chance of survival.
+ We also ignore cabin, since its amount of missing values is too big.  
+ Aparently the chance of survival does not depend on ticket and home-destination. The boat number and body identification number are available only after the Titanic had sunk. So they should not be involved in the model as well.  

Let's drop these irrelevant features.  
```{r}
dropValue <- c("name","cabin","ticket","boat","body","home.dest")
titanic <-  titanic[ , !(names(titanic) %in% dropValue)] 

# source: https://stackoverflow.com/questions/4605206
```

Let's handle missing values and outliers before creating the model.  
  
* feature *age*: Replace missing values by the mean *age*. We also remove all ages above 67 regarding the outliers. 

```{r}
  # Replace the missing values as well as outlier values by the average age
meanAge <- mean(titanic$age, na.rm = TRUE)
titanic$age[is.na(titanic$age)] <- meanAge
titanic$age <- sapply(titanic$age, function(x) ifelse(x > 67, x <- meanAge, x))
```

* feature *fare*: Replace 1 missing value by the mean *fare* in the concerned *pclass*. We also remove all fares above 66,6 regarding the shown outliers. 
```{r}
  # Replace the missing values as well as outlier values by the average fare
meanFare <- mean(titanic$fare, na.rm = TRUE)
titanic$fare[is.na(titanic$fare)] <- meanFare
titanic$fare <- sapply(titanic$fare, function(x) ifelse(x > 66.6, x <- meanFare, x))
```

* feature *embarked*: Replace missing value by the most frequent value.
```{r}
summary(titanic$embarked)
titanic$embarked[is.na(titanic$embarked)] <- "Southampton"
```
  
Let's check once again, whether all missing values are handled.  
``` {r}
any(is.na(titanic))
```
  
As we noticed before, travelling alone or with too many family members seems to decrease the chance of survival. Therefore we decide to create a new feature *numberFamlilyMember*, which contains the number of family member on board and a binary feature *anyFamilyMember*, which indicates whether there is any family member on board. Including *numberFamlilyMember* in the model can tell us whether a large family good for survival is or not, etc.

```{r}
 # define function for anyFamilyMember
myFunction <- function(x,y){
    if (x == '0' | y == '0') {
     return("No")
 } else {
     return("Yes") }} # No if x = 0 or y = 0, else Yes

  # apply myFunction to features sibsp and parch
anyFamilyMember <- mapply(myFunction,titanic$sibsp, titanic$parch)
  # create feature anyFamilyMember
titanic <- data.frame(titanic,anyFamilyMember)
  # factorise anyFamilyMember
titanic$anyFamilyMember <- factor(titanic$anyFamilyMember)

  # define function for numberFamilyMember
myFunction1 <- function(x,y){return(x + y)}
  # apply myFunction1 to features sibsp and parch
numberFamilyMember <- mapply(myFunction1,titanic$sibsp, titanic$parch)
  # create feature numberFamilyMember
titanic <- data.frame(titanic,numberFamilyMember)

# source: https://stackoverflow.com/questions/10078211
```
### Fitting a regression model  
Let's create a train and test data set. Now we still have 1309 passengers in total.
```{r}
train <- titanic[1:1100,] # get the first 1000 passengers for training data
test <- titanic[1101:1309,] # the rest passengers for test data
```

Let's fit the logistic regression model. Hier we use the backward selection to keep only relevant regressors. A backward selection removes every regressor from a model step by step and compare the performance of model with and without this regressor.

```{r}
  # Training a model with all filtered features. Hier we use the training data.
model_full <- glm(survived ~., family = binomial, data = train) 
  # Model after backward selection
model <- step(model_full, direction = "backward") 
```

From now we only use the model after backward selection as reference for the next steps.

### Discussion of model fit, e.g. goodness of fit, significance of regressors
  
Let's see how good our model performs regarding the accuracy.
```{r}
  # Predict the test data. The column survived is hidden during the predicting.
test_predict <- predict(model,type = 'response', newdata = test[-2]) 

  # Assign the results into 2 categories of survival.
survived_predict <- ifelse(test_predict > 0.5,"Yes","No") 

  # Create a confusion matrix and print it.
confusion_matrix <- table(test[,2],survived_predict) 
confusion_matrix

  # Calculate the accuracy and print it.
accuracy <- mean(survived_predict == test$survived)*100
print(paste("The model accuracy is", round(accuracy,digits = 2), "%"))
```

Let's take a look at the significance of regressors in our model.
```{r}
summary(model)
```
The p-value, which ranges between 0 and 1, represents the significance of each regressor. The higher p-value is, the more insignificant is the concerned regressor. *sex* has the lowest p-value, which means that sex of the passenger associate strongly with the target feature *survived*.

Let's calculate the Odd-Ratios.
```{r}
exp(model$coef)
```

Being a male will decrease the chance of surviving (weitere Intepretation please)

```{r}
anova(model, test = "Chisq")
```

### Interpreting the model
There are still several ways to improve the quality of the data set as well as the performance of our predicted model. 

On the one hand, there is a method called cross validation, which is used to limit problems like overfitting (overfitting: a model which contains too many explanatory variables than necessary). 
  
We also notice that the feature *name* actually contains some interesting information, which could be relevant to the predicted model. Many names contain such words like "Master", "Dr.", "Major", etc. Maybe it could somehow affect the result of survival. The code below shows how to split the title from the name. But we did not consider it furthermore because this new feature is extremly unbalanced. The major titles are "Mr." and "Mrs.", which actually determine the sex. Maybe it would be helpful to arrange another titles in some groups to balance this feature somehow. 

```{r eval=FALSE, warning=FALSE}
  # Split title from name
nameSplit <- sapply(titanic$name, function(x) strsplit(x, "[,]"))
nameSplit <- sapply(nameSplit, function(x) x <-  x[2])
nameSplit <- sapply(nameSplit, function(x) strsplit(x, "[.]"))
nameTitle <- sapply(nameSplit, function(x) x[1])

  # See all unique titles 
describe(nameTitle)
  # source: https://www.math.ucla.edu/~anderson/rw1001/library/base/html/strsplit.html  
```  
 



